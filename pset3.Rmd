---
title: "Problem Set 3"
author: "Pieter Quinton"
date: "2/26/2020"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(scales)
library(tidyverse)
```

***Question 1***

**a)**

If the returner knows the server will serve to the forehand, their optimal strategy is to cheat to the forehand because their win probability is 0.5 which is higher than 0.2 for cheating backhand.

If the server knows the returner will cheat to the forehand, their optimal strategy is to serve to the backhand because their win probability is 0.7 which is higher than 0.4 for serving to the forehand.

This does not represent a pure strategy Nash equilibrium because there is no one strategy that is optimal for both players.

**b)**

Payoff for the returner if they cheat forehand: $(x) * (0.5) + (1-x) * (0.3)$

Payoff for the returner if they cheat backhand: $(x) * (0.2) + (1-x) * (0.6)$

Indifference point: 

$(x) * (0.5) + (1-x) * (0.3) = (x) * (0.2) + (1-x) * (0.6)$

$0.2x + 0.3 = 0.6 - 0.4x$

$0.6x = 0.3$

$x = 0.5 = \hat{x}$

**c)**

Payoff for the server if they serve forehand: $(y) * (0.5) + (1-y) * (0.8)$

Payoff for the server if they serve backhand: $(y) * (0.7) + (1-y) * (0.4)$

Indifference point:

$(y) * (0.5) + (1-y) * (0.8) = (y) * (0.7) + (1-y) * (0.4)$

$1.3 - 0.3y = 0.3y + 1.1$

$0.6y = 0.2$

$y = 0.05 = \hat{y}$

**d)**

```{r}
pctWon <- (0.5)*(0.05)*(0.7) + (0.5)*(0.95)*(0.8) + (0.5)*(0.95)*(0.4) + (0.5)*(0.05)*(0.7)
```


$(P_{SF})*(P_{CF})*(0.7) + (P_{SF})*(1-P_{CF})*(0.8) + (1-P_{SF})*(1-P_{CF})*(0.4) + (1-P_{SF})*(P_{CF})*(0.7)$

Where,

Probability of serving forehand = $P_{SF}$ = 0.5

Probability of cheating forehand = $P_{CF}$ = 0.05

Plugging in the values, you get:

$(0.5)*(0.05)*(0.7) + (0.5)*(0.95)*(0.8) + (0.5)*(0.95)*(0.4) + (0.5)*(0.05)*(0.7)$ = `r pctWon`

so the server won `r dollar((pctWon * 100), prefix = NULL)`% of the points.


***Question 2***

**i)**

Expected goals from 20 shots: $20 * 0.057 = 1.14$ goals

**ii)**

Expected points from taking the one goal: 1 (from the overtime average)

Expected points from taking the shots: This can be calculated by taking the probability of scoring more than one goal times two points for a win plus the probability of scoring exactly one goal times one point for the overtime point average plus the probability of scoring no goals times zero points for a loss. To calculate this, I simulated the twenty shots ten-thousand times with a scoring probability of 5.7% and found the proportion of times the team won, lost, or went to overtime based on the number of goals scored.

```{r q2}
hockey <- tibble(rep = 1:10000) %>%
  mutate(goals = rbinom(10000, 20, 0.057)) %>%
  mutate(result = case_when(
    goals > 1 ~ 2,
    goals == 1 ~ 1,
    goals < 1 ~ 0
  )) %>%
  group_by(result) %>%
  summarize(prop = length(result)/10000)

expectedPoints_old <- hockey$prop[2] * 1 + hockey$prop[3] * 2

expectedPoints_today <- hockey$prop[2] * 1.5 + hockey$prop[3] * 2

expectedPoints_new <-  hockey$prop[2] * 1.5 + hockey$prop[3] * 3
```

Based off the simulation, the probability of a loss is `r hockey$prop[1]`, the probability of going to overtime is `r hockey$prop[2]` and the probability of a win is `r hockey$prop[3]`.

Thus, the expected points per game from taking the shots is:

`r hockey$prop[1]` * 0 + `r hockey$prop[2]` * 1 + `r hockey$prop[3]` * 2 = `r expectedPoints_old`

Because `r expectedPoints_old` > 1, the team should take the 20 shots. It is worth noting, however, that if the 10,000 simulations are run repeatedly, there are simulations in which the expected points are below 1. However, on the whole, the value is usually greater than 1. 

**iii)**

The methodology is largely the same. However, the expected points for taking the goal rises to 1.5 because the average points for going to overtime is (2+1)/2 which is 1.5.

The simulation for determining the expected points for taking the shots remains the same. The only thing that changes is the point values for going to overtime. A win still gets 2 points, going to overtime gets 1.5, and a loss still gets 0. 

The new value of points per game from taking the shots is:

`r hockey$prop[1]` * 0 + `r hockey$prop[2]` * 1.5 + `r hockey$prop[3]` * 2 = `r expectedPoints_today` 

Because `r expectedPoints_today` < 1.5, the team should take the guaranteed goal and go to overtime. 

**iv)**

The expected points for taking the goal remains at 1.5 but the value for a regulation win has gone up to 3 so the expected points for taking the shots needs to be re-calculated.

Again using the 10,000 replication of 20 shots simulation data, the only change is the point value for a regulation win (or scoring more than 1 goal in regulation).

`r hockey$prop[1]` * 0 + `r hockey$prop[2]` * 1.5 + `r hockey$prop` * 3 = `r expectedPoints_new`

Because `r expectedPoints_new` > 1.5, the team should opt for the 20 shots over the guaranteed goal. 

**v)**

The expected points for taking the goal returns to 1.

The simulation needs to be re-done for the new goal scoring percentage.

```{r q2 v}

hockeyV <- tibble(rep = 1:10000) %>%
  mutate(goals = rbinom(10000, 20, 0.055)) %>%
  mutate(result = case_when(
    goals > 1 ~ 2,
    goals == 1 ~ 1,
    goals < 1 ~ 0
  )) %>%
  group_by(result) %>%
  summarize(prop = length(result)/10000)

expectedPoints_v <- hockeyV$prop[2] * 1 + hockeyV$prop[3] * 2

```

Based off the new simulation with the percentage at 5.5, the probability of a loss is `r hockeyV$prop[1]`, the probability of going to overtime is `r hockeyV$prop[2]` and the probability of a win is `r hockeyV$prop[3]`.

The new value of points per game from taking the shots is:

`r hockey$prop[1]` * 0 + `r hockey$prop[2]` * 1.5 + `r hockey$prop[3]` * 2 = `r expectedPoints_today` 

Because `r expectedPoints_v` < 1, the team should take the guaranteed goal and go to overtime.

***Question 3***

**i)**

If I were to score the second touchdown, I would be indifferent between kicking the extra point and going for two. Kicking the extra point is a guaranteed point and would send the game to overtime where I would have a 50% chance of winning. Going for two also gives me a 50% chance of winning because I have a 50% probabilty of conversion. 

Therefore, after scoring the first touchdown I should also be indifferent between kicking the extra point and going for two. Scoring a second touchdown is independent of when I kick it or go for two, so the expected payoffs should be the same as after I've scored the second touchdown.

**ii)**

NFL coaches do not usually follow this strategy. They are much more likely to kick the extra point and go to overtime than to risk it and go for two. The deviation from the optimal strategy is do to risk aversion. NFL coaches are afraid of going for two, not making it, and getting crucified by the press/media/analysts. Similary, soccer players rarely kick the ball straight down the middle on PKs because if they miss, they will look like a fool. NFL coaches are scared of looking like a fool for going against "conventional" wisdom. 

***Question 4***

In order to find the optimal bidding value for receiving the kickoff, you would need to calculate how much you value having possession at a given yard line. In other words, what is the expected point differential as a result of receiving the kickoff. That differential should be how much you bid. It is more challenging to calculate the EP of receiving the kickoff because you don't necessarily know where you will start with the ball. You would have to calculate the probability that you take a touchback and the probability that you return the kick and attach those probabilities to the 25 yard line for the touchback and your average return distance for the return. From there, you can calculate the EP of having first and ten at the start of the game from each location weighted by the probability of whether you take the touchback or return it. From the Levitt and Kovash paper, the value of first and ten from your own 25 yard line is just under 1 point. Assuming your team didn't return any kickoffs, you should bid just under 1 point for starting with possession. 

***Question 5***

If you are playing under college overtime rules, you will be more inclined to take risks such as going for it on 4th down than you would if you are playing under NFL overtime rules. The difference in strategy is due to the higher probability of an upset in NFL overtime outcomes. In college, the better team usually wins in overtime meaning you would want to avoid taking your worse team to overtime. In the NFL, on the other hand, the team that wins the coin flip is more likely to win regardless of skill. Thus, you would be more confident in pulling off an overtime upset in the NFL and wouldn't be as risky in your play calling during regulation. 
